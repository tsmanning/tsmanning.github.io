---
title: "Projects"
layout: splash
permalink: /projects/
header:
  overlay_color: "#000"
  overlay_filter: "0.15"
  overlay_image: /assets/images/yosemiteValley2015.jpg
excerpt: #""
intro:
  - excerpt: #""
---

<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<!link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<style>
* {
  box-sizing: border-box;
}

/* Create two columns that float next to each other */
.column {
  float: left;
  padding: 10px;
}

.left{
  width: 40%;
}

.right{
  width: 60%;
}

/* Clear floats after the columns */
.row:after {
  content: "";
  display: table;
  clear: both;
}

/* Responsive layout - makes the two columns stack on top of each other instead of next to each other */
@media screen and (max-width: 800px) {
  .left, .right {
    width: 100%;
  }
}

/* Restrict responsive image to a maximum size, using max-width property */
.responsive {
  width: 100%;
  max-width: 600px;
  height: auto;
}
</style>
</head>

<body>

<!-- Project 1 container -->
<h2>Unconscious inference in motion perception</h2>
<div class="row">
  <div class="column left">
    <img src="/assets/images/UncertProj.png" alt="proj1" width="600" height="369" class="responsive">
  </div>
  <div class="column right">
    <p>People show systematic biases in perceived speeds and directions of motion under many conditions when
       objects are hard to see<span>&#8212;</span>for example, under low contrast conditions like driving in the fog
       or rain. Under these low contrast conditions, object speeds appear to move slower than they actually are in
       the world. This phenomenon has most commonly been explained as an example of unconscious perceptual inference:
       the brain is constantly building a model of object speeds in the world that is a combination of curent speed
       information coming in from the eyes (weighted by uncertainty in that measurement) and expectations about
       speeds (based on previous experience of how often speeds are encountered in the world).</p>

    <p>Another major component of these perceptual speed biases lies in the transformation of retinal speeds into
       world speeds. An ideal observer should perform speed inference in world-centered coordinates, which requires
       a transformation of the uncertainty in the retinal measurements into uncertainty in world speeds. The degree to
       which this uncertainty is scaled depends on distance and retinal eccentricity, which predicts that contrast-dependent
       speed biases should increase with viewing distance.</p>
  </div>
</div>

<!-- Project 2 container -->
<h2>Optimal neural codes for binocular disparity</h2>
<div class="row">
  <div class="column left">
    <img src="/assets/images/DisparityProj.png" alt="proj2" width="600" height="369" class="responsive">
  </div>
  <div class="column right">
    <p>Binocular disparity<span>&#8212;</span>the difference between where the same point in space falls
       on the two eyes<span>&#8212;</span>is a useful visual cue for creating a vivid percept of the world in 3D.
       How does the brain enconde this cue though to maximize its usefulness for vision? In this collaborative project
       with Dr. Emma Alexander, Dr. Gregory DeAngelis, and Dr. Xin Huang we use a combination of image statistics and
       information theoretic analysis of neuronal responses to disparity in different brain areas to answer this question.</p>
  </div>
</div>

<!-- Project 3 container -->
<h2>Extracting heading from retinal images during eye movements</h2>
<div class="row">
  <div class="column left">
    <img src="/assets/images/HeadingProj.png" alt="proj3" width="600" height="369" class="responsive">
  </div>
  <div class="column right">
    <p>The primate visual system has evolved to be highly sensitive to optic flow cues<span>&#8212;</span>complex patterns of motion
       that arise from an observer moving through the world<span>&#8212;</span>to create a vivid percept of self-motion. At the same time,
       we have also have highly motile eyes that constantly select new aspects of the visual scene on which to focus the high-resolution
       fovea. These eye movements produce additional motion on the retina that distorts the optic flow patterns arising from locomotion,
       potentially giving the visual system incorrect information about heading. However, we manage just fine navigating the world, the brain
       must have a way to extract heading information from these distorted images.</p>

    <p>This extraction process could use a forward model of the expected distortions from an impending eye movement ("efference copy") or
       or may simply extract heading-related components of the moving image based on differences in motion patterns caused by eye movements and locomotion.
       We investigated which of these two theories was best supported by recording from heading-sensitive neurons in the macaque monkey brain while
       the monkeys tracked targets with their eyes that moved in front of an optic flow stimulus.</p>
  </div>
</div>

</body>
